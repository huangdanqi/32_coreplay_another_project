#!/usr/bin/env python3
"""
Debug LLM issue with sensor event translation
"""

import asyncio
import json
import sys
from pathlib import Path

# Add paths
sys.path.append('diary_agent')
sys.path.append('sensor_event_agent')

from core.llm_manager import LLMConfigManager
from sensor_event_agent.core.mqtt_handler import MQTTHandler

async def test_llm_basic():
    """Test basic LLM functionality"""
    print("ğŸ§ª Testing basic LLM functionality...")
    
    try:
        llm_manager = LLMConfigManager()
        result = await llm_manager.generate_text_with_failover(
            prompt="è¯·è¯´'ä½ å¥½'",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"
        )
        print(f"âœ… Basic LLM test result: '{result}'")
        return True
    except Exception as e:
        print(f"âŒ Basic LLM test failed: {e}")
        return False

async def test_sensor_prompt():
    """Test the exact sensor prompt that's failing"""
    print("\nğŸ§ª Testing sensor translation prompt...")
    
    try:
        # Load the prompt config
        with open('sensor_event_agent/config/prompt.json', 'r', encoding='utf-8') as f:
            prompt_config = json.load(f)
        
        # Create test MQTT message
        test_message = {
            "sensor_type": "accelerometer",
            "x": 0.1, "y": 0.2, "z": 9.8,
            "count": 3,
            "device_id": "toy_001"
        }
        
        # Parse using MQTT handler
        mqtt_handler = MQTTHandler()
        parsed_data = mqtt_handler.parse_mqtt_message(test_message)
        
        # Prepare the exact prompt
        template = prompt_config["user_prompt_template"]
        user_prompt = template.format(
            mqtt_message=parsed_data["mqtt_message"],
            sensor_data=json.dumps(parsed_data["sensor_data"], ensure_ascii=False),
            event_type=parsed_data["event_type"],
            timestamp=parsed_data["timestamp"],
            device_info=json.dumps(parsed_data["device_info"], ensure_ascii=False)
        )
        
        print(f"ğŸ“ System prompt: {prompt_config['system_prompt'][:100]}...")
        print(f"ğŸ“ User prompt length: {len(user_prompt)} characters")
        
        # Test with LLM
        llm_manager = LLMConfigManager()
        result = await llm_manager.generate_text_with_failover(
            prompt=user_prompt,
            system_prompt=prompt_config["system_prompt"]
        )
        
        print(f"ğŸ” Raw LLM result: '{result}'")
        print(f"ğŸ” Result type: {type(result)}")
        print(f"ğŸ” Result length: {len(result)}")
        
        # Try to parse as JSON
        try:
            parsed_result = json.loads(result.strip())
            print(f"âœ… JSON parsing successful: {parsed_result}")
            description = parsed_result.get("description", "").strip()
            print(f"âœ… Extracted description: '{description}'")
        except json.JSONDecodeError as je:
            print(f"âŒ JSON parsing failed: {je}")
            print(f"ğŸ” Trying to extract manually...")
            
            if ":" in result:
                description = result.split(":", 1)[1].strip().strip('"')
                print(f"âœ… Manually extracted: '{description}'")
            else:
                print(f"âŒ Could not extract description from: '{result}'")
        
        return True
        
    except Exception as e:
        print(f"âŒ Sensor prompt test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Main test function"""
    print("ğŸ”§ Debugging LLM Integration Issue")
    print("=" * 50)
    
    # Test basic LLM
    basic_ok = await test_llm_basic()
    
    # Test sensor prompt
    sensor_ok = await test_sensor_prompt()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ Debug Summary:")
    print(f"   Basic LLM: {'âœ…' if basic_ok else 'âŒ'}")
    print(f"   Sensor prompt: {'âœ…' if sensor_ok else 'âŒ'}")

if __name__ == "__main__":
    asyncio.run(main())
