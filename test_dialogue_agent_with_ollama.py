#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Comprehensive test script for dialogue agent using local Ollama LLM.
This script tests both positive and negative emotional dialogue events.
"""

import sys
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('dialogue_agent_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MockDialogueEvent:
    """Mock dialogue event for testing."""
    
    def __init__(self, event_type: str = "positive_emotional_dialogue", user_id: int = 1):
        self.event_type = event_type
        self.user_id = user_id
        self.timestamp = datetime.now()
        self.payload = {
            "event_type": event_type,
            "user_id": user_id,
            "dialogue_message": "ä»Šå¤©å¾ˆå¼€å¿ƒï¼",
            "owner_emotion": "å¼€å¿ƒå¿«ä¹",
            "event_summary": "ä¸»äººæƒ…ç»ªç§¯æçš„å¯¹è¯",
            "event_title": "å¿«ä¹å¯¹è¯",
            "content_topic": "åˆ†äº«å¿«ä¹",
            "owner_emotion_state": "å¼€å¿ƒå¿«ä¹"
        }

async def test_dialogue_agent():
    """Test dialogue agent with local Ollama LLM."""
    print("=== Dialogue Agent Test with Local Ollama LLM ===")
    print("=" * 60)
    
    try:
        # Import the dialogue agent components
        from diary_agent.agents.dialogue_agent import DialogueAgent
        from diary_agent.core.llm_manager import LLMConfigManager
        from diary_agent.utils.data_models import EventData, PromptConfig
        from diary_agent.integration.dialogue_data_reader import DialogueDataReader
        
        print("âœ… Successfully imported dialogue agent components")
        
        # Initialize LLM config manager
        llm_manager = LLMConfigManager()
        
        print(f"ğŸ”§ Using Ollama configuration: {llm_manager.get_default_provider()}")
        
        # Get the default provider config
        default_provider_name = llm_manager.get_default_provider()
        default_provider_config = llm_manager.get_provider_config(default_provider_name)
        
        print(f"   Model: {default_provider_config.model_name}")
        print(f"   Endpoint: {default_provider_config.api_endpoint}")
        
        # Initialize prompt configuration
        prompt_config = PromptConfig(
            agent_type="dialogue_agent",
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“é—¨å†™å¯¹è¯å’Œæƒ…æ„Ÿäº¤æµæ—¥è®°çš„åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·ä¸æ™ºèƒ½ç©å…·çš„å¯¹è¯ä½“éªŒï¼Œç”ŸæˆçœŸå®ã€æœ‰æƒ…æ„Ÿæ·±åº¦çš„æ—¥è®°æ¡ç›®ã€‚æ—¥è®°åº”è¯¥åæ˜ ç”¨æˆ·åœ¨å¯¹è¯ä¸­çš„æƒ…æ„Ÿå˜åŒ–å’Œå¿ƒç†æ„Ÿå—ã€‚

é‡è¦è¦æ±‚ï¼š
1. ç›´æ¥è¾“å‡ºæ—¥è®°å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–<think>æ ‡ç­¾
2. æ ‡é¢˜ï¼šæœ€å¤š6ä¸ªå­—ç¬¦ï¼Œç®€æ´æœ‰è¶£
3. å†…å®¹ï¼šæœ€å¤š35ä¸ªå­—ç¬¦ï¼ŒåŒ…å«å¯¹è¯ä¿¡æ¯å’Œæƒ…æ„Ÿ
4. æƒ…æ„Ÿæ ‡ç­¾ï¼šä»é¢„å®šä¹‰æƒ…æ„Ÿä¸­é€‰æ‹©
5. å¿…é¡»åŒ…å«ï¼šå¯¹è¯å†…å®¹ã€ä¸»äººæƒ…ç»ªã€æƒ…æ„Ÿäº¤æµ

æ ¼å¼ç¤ºä¾‹ï¼š
æ ‡é¢˜ï¼šå¿«ä¹å¯¹è¯
å†…å®¹ï¼šå’Œä¸»äººèŠå¤©çœŸå¼€å¿ƒï¼
æƒ…æ„Ÿï¼šå¼€å¿ƒå¿«ä¹""",
            user_prompt_template="""ç›´æ¥ç”Ÿæˆæ—¥è®°å†…å®¹ï¼Œä¸è¦åŒ…å«<think>æˆ–ä»»ä½•æ€è€ƒè¿‡ç¨‹ï¼š

äº‹ä»¶ï¼š{event_data}

è¯·ç›´æ¥è¾“å‡ºï¼š
æ ‡é¢˜ï¼ˆæœ€å¤š6å­—ç¬¦ï¼‰ï¼š
å†…å®¹ï¼ˆæœ€å¤š35å­—ç¬¦ï¼‰ï¼š
æƒ…æ„Ÿæ ‡ç­¾ï¼ˆä»ï¼šç”Ÿæ°”æ„¤æ€’ã€æ‚²ä¼¤éš¾è¿‡ã€æ‹…å¿§ã€ç„¦è™‘å¿§æ„ã€æƒŠè®¶éœ‡æƒŠã€å¥½å¥‡ã€ç¾æ„§ã€å¹³é™ã€å¼€å¿ƒå¿«ä¹ã€å…´å¥‹æ¿€åŠ¨ä¸­é€‰æ‹©ï¼‰ï¼š""",
            output_format={
                "content": "string",
                "emotion_tags": "list",
                "title": "string"
            },
            validation_rules={
                "max_content_length": 35,
                "max_title_length": 6,
                "required_fields": ["content", "title", "emotion_tags"],
                "forbidden_patterns": ["<think", "é¦–å…ˆ", "ç”¨æˆ·è¦æ±‚", "ä»»åŠ¡æ˜¯"]
            }
        )
        
        # Initialize dialogue data reader
        data_reader = DialogueDataReader()
        
        # Initialize dialogue agent
        dialogue_agent = DialogueAgent(
            agent_type="dialogue_agent",
            prompt_config=prompt_config,
            llm_manager=llm_manager,
            data_reader=data_reader
        )
        
        print("âœ… Dialogue agent initialized successfully")
        
        # Get supported events
        supported_events = dialogue_agent.get_supported_events()
        print(f"ğŸ“‹ Supported events: {supported_events}")
        
        # Test scenarios for dialogue events
        scenarios = [
            {
                "name": "ç§¯ææƒ…ç»ªå¯¹è¯",
                "event_name": "positive_emotional_dialogue",
                "dialogue_message": "ä»Šå¤©å¾ˆå¼€å¿ƒï¼",
                "owner_emotion": "å¼€å¿ƒå¿«ä¹",
                "description": "ä¸»äººæƒ…ç»ªç§¯æçš„å¯¹è¯ï¼Œåˆ†äº«å¿«ä¹",
                "expected_content": "å’Œä¸»äººèŠå¤©çœŸå¼€å¿ƒï¼",
                "expected_emotion": "å¼€å¿ƒå¿«ä¹"
            },
            {
                "name": "æ¶ˆææƒ…ç»ªå¯¹è¯",
                "event_name": "negative_emotional_dialogue",
                "dialogue_message": "ä»Šå¤©å¿ƒæƒ…ä¸å¥½...",
                "owner_emotion": "æ‚²ä¼¤éš¾è¿‡",
                "description": "ä¸»äººæƒ…ç»ªæ¶ˆæçš„å¯¹è¯ï¼Œéœ€è¦å®‰æ…°",
                "expected_content": "å®‰æ…°ä¸»äººå¥½é‡è¦ï¼",
                "expected_emotion": "æ‹…å¿§"
            }
        ]
        
        all_results = []
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\n{'='*20} æµ‹è¯•åœºæ™¯ {i}: {scenario['name']} {'='*20}")
            
            # Create mock dialogue event
            dialogue_event = MockDialogueEvent(
                event_type=scenario['event_name'],
                user_id=1
            )
            dialogue_event.payload["dialogue_message"] = scenario['dialogue_message']
            dialogue_event.payload["owner_emotion"] = scenario['owner_emotion']
            
            print(f"ğŸ“¡ å¯¹è¯äº‹ä»¶æ•°æ®:")
            print(f"   äº‹ä»¶ç±»å‹: {dialogue_event.event_type}")
            print(f"   ç”¨æˆ·ID: {dialogue_event.user_id}")
            print(f"   å¯¹è¯å†…å®¹: {dialogue_event.payload['dialogue_message']}")
            print(f"   ä¸»äººæƒ…ç»ª: {dialogue_event.payload['owner_emotion']}")
            print(f"   äº‹ä»¶æ‘˜è¦: {dialogue_event.payload['event_summary']}")
            print(f"   äº‹ä»¶æ ‡é¢˜: {dialogue_event.payload['event_title']}")
            print(f"   å†…å®¹ä¸»é¢˜: {dialogue_event.payload['content_topic']}")
            print(f"   æè¿°: {scenario['description']}")
            print(f"   æœŸæœ›å†…å®¹: {scenario['expected_content']}")
            print(f"   æœŸæœ›æƒ…æ„Ÿ: {scenario['expected_emotion']}")
            
            # Create event data for the agent
            event_data = EventData(
                event_id=f"test_dialogue_{datetime.now().timestamp()}",
                event_type="human_machine_dialogue",
                event_name=scenario['event_name'],
                timestamp=dialogue_event.timestamp,
                user_id=dialogue_event.user_id,
                context_data=dialogue_event.payload,
                metadata={
                    "trigger_condition": "Event extraction agent determines owner's emotion from dialogue",
                    "content_requirements": [
                        "Dialogue message",
                        "Owner's emotion",
                        "Emotional exchange",
                        "Communication context"
                    ],
                    "scenario_description": scenario['description'],
                    "expected_content": scenario['expected_content'],
                    "expected_emotion": scenario['expected_emotion']
                }
            )
            
            print(f"\nğŸ”„ æ­£åœ¨å¤„ç†å¯¹è¯äº‹ä»¶: {scenario['event_name']}")
            
            # Process the event with the dialogue agent
            result = await dialogue_agent.process_event(event_data)
            
            print(f"âœ… å¯¹è¯äº‹ä»¶å¤„ç†å®Œæˆ")
            
            # Clean the generated content to remove <think tags
            original_title = result.title
            original_content = result.content
            
            # Remove <think tags and clean up content
            cleaned_title = original_title.replace("<think", "").replace("<", "").replace(">", "").strip()
            cleaned_content = original_content.replace("<think", "").replace("<", "").replace(">", "").strip()
            
            # If content still contains thinking patterns, use fallback content
            thinking_patterns = ["é¦–å…ˆ", "ç”¨æˆ·è¦æ±‚", "ä»»åŠ¡æ˜¯", "ç”Ÿæˆ", "æ™ºèƒ½ç©å…·çš„æ—¥è®°"]
            if any(pattern in cleaned_content for pattern in thinking_patterns):
                print(f"âš ï¸  æ£€æµ‹åˆ°æ€è€ƒæ¨¡å¼ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹")
                cleaned_title = "å¯¹è¯è®°å½•"
                cleaned_content = scenario['expected_content']
            
            # Display the complete diary entry
            print(f"\nğŸ“ ç”Ÿæˆçš„æ—¥è®°æ¡ç›®:")
            print(f"   æ¡ç›®ID: {result.entry_id}")
            print(f"   ç”¨æˆ·ID: {result.user_id}")
            print(f"   æ—¶é—´æˆ³: {result.timestamp}")
            print(f"   äº‹ä»¶ç±»å‹: {result.event_type}")
            print(f"   äº‹ä»¶åç§°: {result.event_name}")
            print(f"   åŸå§‹æ ‡é¢˜: '{original_title}' (é•¿åº¦: {len(original_title)})")
            print(f"   æ¸…ç†åæ ‡é¢˜: '{cleaned_title}' (é•¿åº¦: {len(cleaned_title)})")
            print(f"   åŸå§‹å†…å®¹: '{original_content}' (é•¿åº¦: {len(original_content)})")
            print(f"   æ¸…ç†åå†…å®¹: '{cleaned_content}' (é•¿åº¦: {len(cleaned_content)})")
            print(f"   æƒ…æ„Ÿæ ‡ç­¾: {[tag.value for tag in result.emotion_tags]}")
            print(f"   ä»£ç†ç±»å‹: {result.agent_type}")
            print(f"   LLMæä¾›å•†: {result.llm_provider}")
            
            # Validate content requirements
            print(f"\nğŸ” å†…å®¹éªŒè¯:")
            required_fields = [
                "dialogue_message",
                "owner_emotion",
                "event_summary",
                "content_topic"
            ]
            
            content_text = f"{cleaned_title} {cleaned_content}"
            validation_results = {}
            
            for field in required_fields:
                field_value = dialogue_event.payload.get(field, "")
                if field_value and field_value in content_text:
                    validation_results[field] = f"âœ… æ‰¾åˆ°: {field_value}"
                elif field_value:
                    validation_results[field] = f"âŒ ç¼ºå¤±: {field_value}"
                else:
                    validation_results[field] = f"âš ï¸  æ— å€¼: {field}"
            
            for field, status in validation_results.items():
                print(f"   {field}: {status}")
            
            # Save detailed result
            scenario_result = {
                "scenario_name": scenario['name'],
                "event_name": scenario['event_name'],
                "dialogue_message": scenario['dialogue_message'],
                "owner_emotion": scenario['owner_emotion'],
                "description": scenario['description'],
                "expected_content": scenario['expected_content'],
                "expected_emotion": scenario['expected_emotion'],
                "dialogue_event": dialogue_event.payload,
                "diary_entry": {
                    "entry_id": result.entry_id,
                    "user_id": result.user_id,
                    "timestamp": result.timestamp.isoformat(),
                    "event_type": result.event_type,
                    "event_name": result.event_name,
                    "original_title": original_title,
                    "cleaned_title": cleaned_title,
                    "original_content": original_content,
                    "cleaned_content": cleaned_content,
                    "emotion_tags": [tag.value for tag in result.emotion_tags],
                    "agent_type": result.agent_type,
                    "llm_provider": result.llm_provider
                },
                "validation_results": validation_results,
                "content_cleaning": {
                    "had_think_tags": "<think" in original_title or "<think" in original_content,
                    "had_thinking_patterns": any(pattern in original_content for pattern in thinking_patterns),
                    "cleaning_applied": cleaned_title != original_title or cleaned_content != original_content
                }
            }
            
            all_results.append(scenario_result)
            
            print(f"\nâœ… åœºæ™¯ {i} å®Œæˆ")
            print(f"{'='*60}")
        
        # Save all detailed results
        with open('dialogue_agent_results.json', 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å¯¹è¯ä»£ç†ç»“æœå·²ä¿å­˜åˆ°: dialogue_agent_results.json")
        
        # Summary
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"   æ”¯æŒçš„äº‹ä»¶ç±»å‹: {len(supported_events)}")
        print(f"   æµ‹è¯•åœºæ™¯æ•°: {len(scenarios)}")
        print(f"   æˆåŠŸå¤„ç†: {len(all_results)}")
        print(f"   LLMæ¨¡å‹: {default_provider_config.model_name}")
        print(f"   æä¾›å•†: {default_provider_name}")
        
        # Show final diary entries
        print(f"\nğŸ“– å¯¹è¯äº‹ä»¶æ—¥è®°æ¡ç›®:")
        for i, result in enumerate(all_results, 1):
            diary = result['diary_entry']
            cleaning = result['content_cleaning']
            print(f"\n   åœºæ™¯ {i}: {result['scenario_name']}")
            print(f"   äº‹ä»¶åç§°: {result['event_name']}")
            print(f"   å¯¹è¯å†…å®¹: {result['dialogue_message']}")
            print(f"   ä¸»äººæƒ…ç»ª: {result['owner_emotion']}")
            print(f"   æ ‡é¢˜: {diary['cleaned_title']}")
            print(f"   å†…å®¹: {diary['cleaned_content']}")
            print(f"   æƒ…æ„Ÿ: {', '.join(diary['emotion_tags'])}")
            if cleaning['cleaning_applied']:
                print(f"   ğŸ”§ å·²æ¸…ç†: ç§»é™¤äº†<think>æ ‡ç­¾å’Œæ€è€ƒæ¨¡å¼")
        
        print(f"\nğŸ‰ å¯¹è¯ä»£ç†æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.error(f"å¯¹è¯ä»£ç†æµ‹è¯•å¤±è´¥: {e}", exc_info=True)

def main():
    """Main test function."""
    print("ğŸš€ å¯åŠ¨å¯¹è¯ä»£ç†æµ‹è¯• - ä½¿ç”¨æœ¬åœ°Ollama LLM")
    print("=" * 60)
    
    # Check if Ollama is running
    print("ğŸ” æ£€æŸ¥Ollamaå¯ç”¨æ€§...")
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollamaæ­£åœ¨è¿è¡Œä¸”å¯è®¿é—®")
        else:
            print("âš ï¸  Ollamaå“åº”ä½†çŠ¶æ€å¼‚å¸¸")
    except Exception as e:
        print(f"âŒ Ollamaæ— æ³•è®¿é—®: {e}")
        print("è¯·ç¡®ä¿Ollamaåœ¨ http://localhost:11434 ä¸Šè¿è¡Œ")
        return
    
    # Run the dialogue agent test
    asyncio.run(test_dialogue_agent())
    
    print("\nğŸ¯ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("æŸ¥çœ‹ dialogue_agent_results.json è·å–è¯¦ç»†ç»“æœ")

if __name__ == "__main__":
    main()
