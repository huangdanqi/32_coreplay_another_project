"""
Claim Event Function Test with Local LLM (Ollama)

This script tests the Claim Event function using a local LLM (Ollama Qwen3)
to generate diary entries for device binding events.
"""

import sys
import asyncio
import json
from datetime import datetime
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

async def test_claim_event_with_local_llm():
    """Test Claim Event function using local LLM."""
    print("ğŸ¯ Claim Event Function Test with Local LLM")
    print("="*60)
    
    try:
        # Import necessary components
        from diary_agent.utils.data_models import EventData, DiaryEntry, EmotionalTag, PromptConfig
        from diary_agent.core.llm_manager import LLMConfigManager
        from diary_agent.agents.adoption_agent import AdoptionAgent
        from diary_agent.integration.adoption_data_reader import AdoptionDataReader
        
        print("âœ… Successfully imported diary agent components")
        
        # 1. Create Ollama configuration
        print("\nğŸ”§ Setting up local LLM configuration...")
        
        ollama_config = {
            "providers": {
                "ollama_qwen3": {
                    "provider_name": "ollama_qwen3",
                    "api_endpoint": "http://localhost:11434/api/generate",
                    "api_key": "not-required",
                    "model_name": "qwen3:4b",
                    "max_tokens": 150,
                    "temperature": 0.7,
                    "timeout": 60,
                    "retry_attempts": 3,
                    "provider_type": "ollama",
                    "enabled": True,
                    "priority": 1,
                    "capabilities": ["general", "creative", "local"]
                }
            },
            "model_selection": {
                "default_provider": "ollama_qwen3",
                "fallback_providers": [],
                "auto_switch_rules": {
                    "enable_auto_switch": False,
                    "switch_on_failure": False,
                    "switch_on_timeout": False
                }
            }
        }
        
        # Save configuration to temporary file
        config_file = "test_claim_event_llm_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(ollama_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Created LLM configuration: {config_file}")
        
        # 2. Initialize LLM manager with local configuration
        llm_manager = LLMConfigManager(config_file)
        print("âœ… LLM manager initialized")
        
        # 3. Create sample device binding event
        print("\nğŸ“± Creating device binding event...")
        
        owner_info = {
            "user_id": 789,
            "name": "å°å",
            "nickname": "å°åä¸»äºº",
            "age": 30,
            "gender": "male",
            "location": "æ·±åœ³",
            "interests": ["ç¼–ç¨‹", "æ¸¸æˆ", "éŸ³ä¹"],
            "personality": "lively",
            "emotional_baseline": {"x": 1, "y": 2},
            "intimacy_level": 40
        }
        
        event_data = EventData(
            event_id="local_llm_claim_001",
            event_type="adoption_event",
            event_name="toy_claimed",
            timestamp=datetime.now(),
            user_id=owner_info["user_id"],
            context_data={
                "device_id": "smart_toy_local_001",
                "binding_method": "bluetooth_pairing",
                "binding_timestamp": datetime.now().isoformat(),
                "device_type": "smart_toy",
                "device_name": "æ™ºèƒ½æœºå™¨äºº",
                "bluetooth_mac": "AA:BB:CC:DD:EE:FF"
            },
            metadata={
                "owner_info": owner_info,
                "claim_method": "bluetooth",
                "toy_model": "SMART_ROBOT_V3",
                "binding_location": "office",
                "network_type": "bluetooth"
            }
        )
        
        print("âœ… Created device binding event:")
        print(f"   Device: {event_data.context_data['device_name']}")
        print(f"   Owner: {event_data.metadata['owner_info']['name']}")
        print(f"   Method: {event_data.context_data['binding_method']}")
        print(f"   Location: {event_data.metadata['binding_location']}")
        
        # 4. Create adoption agent with local LLM
        print("\nğŸ¤– Setting up adoption agent with local LLM...")
        
        # Create prompt configuration for adoption agent
        prompt_config = PromptConfig(
            agent_type="adoption_agent",
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“é—¨å¤„ç†ç©å…·è®¤é¢†äº‹ä»¶çš„AIåŠ©æ‰‹ã€‚å½“ç”¨æˆ·é€šè¿‡è®¾å¤‡ç»‘å®šè®¤é¢†ç©å…·æ—¶ï¼Œä½ éœ€è¦ç”Ÿæˆä¸€æ®µç®€çŸ­ã€æ¸©é¦¨çš„æ—¥è®°å†…å®¹ã€‚

è¦æ±‚ï¼š
1. æ ‡é¢˜æœ€å¤š6ä¸ªå­—ç¬¦
2. å†…å®¹æœ€å¤š35ä¸ªå­—ç¬¦ï¼Œå¯ä»¥åŒ…å«emoji
3. è¡¨è¾¾è¢«è®¤é¢†çš„å–œæ‚¦å’Œå…´å¥‹
4. åŒ…å«ä¸»äººçš„åå­—
5. ä½¿ç”¨ä¸­æ–‡è¡¨è¾¾

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
    "title": "æ ‡é¢˜",
    "content": "å†…å®¹",
    "emotion_tags": ["æƒ…ç»ªæ ‡ç­¾"]
}""",
            user_prompt_template="""è¯·ä¸ºä»¥ä¸‹è®¤é¢†äº‹ä»¶ç”Ÿæˆæ—¥è®°å†…å®¹ï¼š

äº‹ä»¶åç§°: {event_name}
ä¸»äººä¿¡æ¯: {owner_info}
è®¾å¤‡ä¿¡æ¯: {device_info}
ç»‘å®šæ–¹æ³•: {binding_method}

è¯·ç”Ÿæˆæ¸©é¦¨çš„è®¤é¢†æ—¥è®°å†…å®¹ã€‚""",
            output_format={
                "title": "string",
                "content": "string",
                "emotion_tags": "list"
            },
            validation_rules={
                "title_max_length": 6,
                "content_max_length": 35
            }
        )
        
        # Create mock data reader
        mock_data_reader = type('MockDataReader', (), {
            'read_event_context': lambda *args, **kwargs: type('MockContext', (), {
                'user_profile': event_data.metadata["owner_info"],
                'event_details': {
                    "event_name": "toy_claimed",
                    "device_id": event_data.context_data["device_id"],
                    "device_name": event_data.context_data["device_name"],
                    "binding_method": event_data.context_data["binding_method"]
                },
                'environmental_context': {},
                'social_context': {},
                'emotional_context': {},
                'temporal_context': {"timestamp": event_data.timestamp}
            })(),
            'get_user_preferences': lambda *args, **kwargs: {},
            'get_adoption_event_info': lambda *args, **kwargs: {"probability": 1.0},
            'get_supported_events': lambda *args, **kwargs: ["toy_claimed"]
        })()
        
        # Create adoption agent
        adoption_agent = AdoptionAgent(
            agent_type="adoption_agent",
            prompt_config=prompt_config,
            llm_manager=llm_manager,
            data_reader=mock_data_reader
        )
        
        print("âœ… Adoption agent created with local LLM")
        
        # 5. Test LLM connection
        print("\nğŸ” Testing local LLM connection...")
        
        try:
            current_provider = llm_manager.get_current_provider()
            print(f"âœ… Current LLM provider: {current_provider.provider_name}")
            print(f"âœ… Model: {current_provider.model_name}")
            print(f"âœ… Endpoint: {current_provider.api_endpoint}")
            
            # Test simple generation
            test_prompt = "è¯·ç”¨ä¸€å¥è¯å›ç­”ï¼šä½ å¥½"
            test_response = await llm_manager.generate_text_with_failover(test_prompt)
            print(f"âœ… LLM test response: {test_response[:50]}...")
            
        except Exception as e:
            print(f"âŒ LLM connection test failed: {e}")
            print("ğŸ’¡ Make sure Ollama is running: ollama serve")
            print("ğŸ’¡ Make sure Qwen3 is installed: ollama pull qwen3")
            return False
        
        # 6. Process claim event with local LLM
        print("\nğŸ¯ Processing claim event with local LLM...")
        
        try:
            # Process the event
            diary_entry = await adoption_agent.process_event(event_data)
            
            if diary_entry:
                print("âœ… Successfully generated diary entry with local LLM!")
                print(f"\nğŸ“ Generated Diary Entry:")
                print(f"   Title: {diary_entry.title}")
                print(f"   Content: {diary_entry.content}")
                print(f"   Emotions: {[tag.value for tag in diary_entry.emotion_tags]}")
                print(f"   User ID: {diary_entry.user_id}")
                print(f"   Event Name: {diary_entry.event_name}")
                print(f"   LLM Provider: {diary_entry.llm_provider}")
                
                # Verify content requirements
                assert len(diary_entry.title) <= 6
                assert len(diary_entry.content) <= 35
                assert event_data.metadata["owner_info"]["name"] in diary_entry.content
                assert "è®¤é¢†" in diary_entry.content or "ä¸»äºº" in diary_entry.content
                print("âœ… Content validation passed")
                
                # Verify specification compliance
                print("\nğŸ“‹ Specification Compliance Check:")
                print(f"âœ… Trigger condition (device binding): VERIFIED")
                print(f"âœ… Content requirement (owner's personal info): VERIFIED")
                print(f"âœ… Local LLM generation: VERIFIED")
                print(f"âœ… Content length validation: VERIFIED")
                
                return True
            else:
                print("âŒ Failed to generate diary entry")
                return False
                
        except Exception as e:
            print(f"âŒ Error processing claim event: {e}")
            import traceback
            traceback.print_exc()
            return False
            
    except Exception as e:
        print(f"âŒ Error in test setup: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_multiple_claim_events():
    """Test multiple claim events with local LLM."""
    print("\nğŸ”„ Testing multiple claim events with local LLM...")
    
    try:
        from diary_agent.utils.data_models import EventData, DiaryEntry, EmotionalTag, PromptConfig
        from diary_agent.core.llm_manager import LLMConfigManager
        from diary_agent.agents.adoption_agent import AdoptionAgent
        
        # Use the same configuration
        llm_manager = LLMConfigManager("test_claim_event_llm_config.json")
        
        # Create multiple events
        events = []
        for i in range(3):
            owner_info = {
                "user_id": 1000 + i,
                "name": f"ç”¨æˆ·{i+1}",
                "nickname": f"ä¸»äºº{i+1}",
                "personality": "lively" if i % 2 == 0 else "clam"
            }
            
            event_data = EventData(
                event_id=f"multi_claim_{i+1}",
                event_type="adoption_event",
                event_name="toy_claimed",
                timestamp=datetime.now(),
                user_id=owner_info["user_id"],
                context_data={
                    "device_id": f"device_{i+1}",
                    "binding_method": "qr_scan" if i % 2 == 0 else "bluetooth",
                    "device_name": f"æ™ºèƒ½ç©å…·{i+1}"
                },
                metadata={"owner_info": owner_info}
            )
            events.append(event_data)
        
        # Create adoption agent
        prompt_config = PromptConfig(
            agent_type="adoption_agent",
            system_prompt="ç”Ÿæˆè®¤é¢†äº‹ä»¶çš„æ—¥è®°å†…å®¹ï¼ŒåŒ…å«ä¸»äººåå­—ï¼Œè¡¨è¾¾å–œæ‚¦ã€‚",
            user_prompt_template="ä¸º{event_name}äº‹ä»¶ç”Ÿæˆæ—¥è®°ï¼Œä¸»äººæ˜¯{owner_info}",
            output_format={"title": "string", "content": "string", "emotion_tags": "list"},
            validation_rules={"title_max_length": 6, "content_max_length": 35}
        )
        
        mock_data_reader = type('MockDataReader', (), {
            'read_event_context': lambda *args, **kwargs: type('MockContext', (), {
                'user_profile': {"name": "æµ‹è¯•ç”¨æˆ·"},
                'event_details': {"event_name": "toy_claimed"},
                'environmental_context': {},
                'social_context': {},
                'emotional_context': {},
                'temporal_context': {"timestamp": datetime.now()}
            })(),
            'get_user_preferences': lambda *args, **kwargs: {},
            'get_adoption_event_info': lambda *args, **kwargs: {"probability": 1.0},
            'get_supported_events': lambda *args, **kwargs: ["toy_claimed"]
        })()
        
        adoption_agent = AdoptionAgent(
            agent_type="adoption_agent",
            prompt_config=prompt_config,
            llm_manager=llm_manager,
            data_reader=mock_data_reader
        )
        
        # Process each event
        results = []
        for i, event_data in enumerate(events):
            print(f"\nå¤„ç†äº‹ä»¶ {i+1}: {event_data.metadata['owner_info']['name']}")
            
            try:
                diary_entry = await adoption_agent.process_event(event_data)
                if diary_entry:
                    results.append(diary_entry)
                    print(f"âœ… ç”ŸæˆæˆåŠŸ: {diary_entry.content}")
                else:
                    print(f"âŒ ç”Ÿæˆå¤±è´¥")
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {e}")
        
        print(f"\nğŸ“Š å¤„ç†ç»“æœ: {len(results)}/{len(events)} æˆåŠŸ")
        return len(results) > 0
        
    except Exception as e:
        print(f"âŒ å¤šäº‹ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """Main test function."""
    print("ğŸš€ Claim Event Function Test with Local LLM")
    print("="*60)
    
    # Test single claim event
    success = await test_claim_event_with_local_llm()
    
    if success:
        # Test multiple events
        multi_success = await test_multiple_claim_events()
        
        print("\nğŸ‰ Test Summary")
        print("="*30)
        print("âœ… Single claim event: PASSED")
        print(f"{'âœ…' if multi_success else 'âŒ'} Multiple events: {'PASSED' if multi_success else 'FAILED'}")
        print("âœ… Local LLM integration: PASSED")
        print("âœ… Specification compliance: PASSED")
        
        print("\nğŸš€ Claim Event function is working with local LLM!")
        print("The function successfully generates diary entries using Ollama Qwen3.")
        
        return 0
    else:
        print("\nâŒ Test failed")
        print("\nğŸ”§ Troubleshooting:")
        print("1. Make sure Ollama is running: ollama serve")
        print("2. Make sure Qwen3 is installed: ollama pull qwen3")
        print("3. Test Ollama connection: python test_ollama_connection.py")
        
        return 1

if __name__ == "__main__":
    # Clean up config file on exit
    import atexit
    atexit.register(lambda: Path("test_claim_event_llm_config.json").unlink(missing_ok=True))
    
    sys.exit(asyncio.run(main()))
